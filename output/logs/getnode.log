2025-05-18 18:47:57,169 - getnode - INFO - main.py:25 - === 开始执行爬虫任务 ===
2025-05-18 18:48:14,051 - getnode - INFO - crawler.py:133 - 仓库搜索完成 | 总扫描仓库: 233 有效仓库: 120 跳过: 113
2025-05-18 18:48:14,051 - getnode - INFO - main.py:30 - 发现 120 个相关仓库
2025-05-18 18:48:14,051 - getnode - INFO - main.py:34 - 开始收集节点文件...
2025-05-18 18:48:52,927 - getnode - INFO - crawler.py:56 - 已使用API次数: 100/小时
2025-05-18 18:49:28,960 - getnode - INFO - crawler.py:56 - 已使用API次数: 200/小时
2025-05-18 18:50:06,497 - getnode - INFO - crawler.py:56 - 已使用API次数: 300/小时
2025-05-18 18:50:43,594 - getnode - INFO - crawler.py:56 - 已使用API次数: 400/小时
2025-05-18 18:51:20,477 - getnode - INFO - crawler.py:56 - 已使用API次数: 500/小时
2025-05-18 18:51:56,107 - getnode - INFO - crawler.py:56 - 已使用API次数: 600/小时
2025-05-18 18:52:31,467 - getnode - INFO - crawler.py:56 - 已使用API次数: 700/小时
2025-05-18 18:53:07,111 - getnode - INFO - crawler.py:56 - 已使用API次数: 800/小时
2025-05-18 18:53:46,447 - getnode - INFO - crawler.py:56 - 已使用API次数: 900/小时
2025-05-18 18:54:24,275 - getnode - INFO - crawler.py:51 - 已使用API次数: 1000/小时
2025-05-18 18:54:58,751 - getnode - INFO - crawler.py:56 - 已使用API次数: 1100/小时
2025-05-18 18:55:33,614 - getnode - INFO - crawler.py:56 - 已使用API次数: 1200/小时
2025-05-18 18:56:09,302 - getnode - INFO - crawler.py:56 - 已使用API次数: 1300/小时
2025-05-18 18:56:44,312 - getnode - INFO - crawler.py:56 - 已使用API次数: 1400/小时
2025-05-18 18:57:20,403 - getnode - INFO - crawler.py:56 - 已使用API次数: 1500/小时
2025-05-18 18:57:56,037 - getnode - INFO - crawler.py:56 - 已使用API次数: 1600/小时
2025-05-18 18:58:38,146 - getnode - INFO - crawler.py:56 - 已使用API次数: 1700/小时
2025-05-18 18:59:19,918 - getnode - INFO - crawler.py:56 - 已使用API次数: 1800/小时
2025-05-18 18:59:20,649 - getnode - INFO - main.py:38 - 总共发现 105 个节点文件
2025-05-18 18:59:20,649 - getnode - INFO - nodesjob.py:21 - 开始处理链接集合，共 105 个链接
2025-05-18 19:00:23,004 - getnode - INFO - nodesjob.py:78 - 链接处理完成。成功: 52, 失败: 53
2025-05-18 19:00:28,079 - getnode - INFO - history_manager.py:23 - 成功加载历史节点数量: 16692
2025-05-18 19:00:28,079 - getnode - ERROR - nodesjob.py:183 - 解析Clash配置文件时发生未知错误: 无效的配置类型
Traceback (most recent call last):
  File "d:\Learning\getnode\src\nodesjob.py", line 146, in _parse_clash_config_content
    raise ValueError("无效的配置类型")
ValueError: 无效的配置类型
2025-05-18 19:00:28,079 - getnode - INFO - history_manager.py:44 - 合并后总节点数: 11378
2025-05-18 19:00:28,079 - getnode - INFO - nodesjob.py:593 - 开始保存节点结果到目录: output
2025-05-18 19:00:28,181 - getnode - INFO - nodesjob.py:611 - 开始写入输出文件...
2025-05-18 19:00:32,029 - getnode - INFO - nodesjob.py:620 - 成功生成订阅文件，总节点数: 11224
2025-05-18 19:00:32,029 - getnode - INFO - tester.py:74 - === 批量测试开始 | 总节点数: 11378 ===
2025-05-18 19:01:11,369 - getnode - INFO - tester.py:105 - === 批量测试完成 | 有效节点: 11374 (成功率: 100.0%) ===
2025-05-18 19:01:11,369 - getnode - INFO - nodesjob.py:593 - 开始保存节点结果到目录: speedtest
2025-05-18 19:01:11,469 - getnode - INFO - nodesjob.py:611 - 开始写入输出文件...
2025-05-18 19:01:15,366 - getnode - INFO - nodesjob.py:620 - 成功生成订阅文件，总节点数: 11220
2025-05-18 19:01:15,584 - getnode - INFO - main.py:81 - 
=== 文件处理统计 ===
• 扫描文件总数: 13014
• 因大小跳过:   127 (1.0%)
• 有效处理文件: 12887
=== 节点处理统计 ===
• 扫描节点总数: 13313
• 节点去重数:   1935
• 真实节点数:   11378
2025-05-18 21:19:47,239 - getnode - INFO - main.py:25 - === 开始执行爬虫任务 ===
2025-05-18 21:20:00,453 - getnode - INFO - crawler.py:133 - 仓库搜索完成 | 总扫描仓库: 160 有效仓库: 60 跳过: 100
2025-05-18 21:20:00,453 - getnode - INFO - main.py:30 - 发现 60 个相关仓库
2025-05-18 21:20:00,453 - getnode - INFO - main.py:34 - 开始收集节点文件...
2025-05-18 21:20:36,271 - getnode - INFO - crawler.py:56 - 已使用API次数: 100/小时
2025-05-18 21:21:16,725 - getnode - INFO - crawler.py:56 - 已使用API次数: 200/小时
2025-05-18 21:21:53,775 - getnode - INFO - crawler.py:56 - 已使用API次数: 300/小时
2025-05-18 21:22:31,229 - getnode - INFO - crawler.py:56 - 已使用API次数: 400/小时
2025-05-18 21:23:00,075 - getnode - INFO - main.py:38 - 总共发现 151 个节点文件
2025-05-18 21:23:00,076 - getnode - INFO - nodesjob.py:21 - 开始处理链接集合，共 151 个链接
2025-05-18 21:24:40,479 - getnode - INFO - nodesjob.py:78 - 链接处理完成。成功: 114, 失败: 37
2025-05-18 21:24:43,687 - getnode - INFO - history_manager.py:23 - 成功加载历史节点数量: 11378
2025-05-18 21:24:44,993 - getnode - INFO - history_manager.py:34 - 新节点：16629,
历史节点：11378
2025-05-18 21:24:45,206 - getnode - INFO - history_manager.py:53 - 合并后总节点数: 27367
2025-05-18 21:24:45,206 - getnode - INFO - nodesjob.py:591 - 开始保存节点结果到目录: output
2025-05-18 21:24:45,405 - getnode - INFO - nodesjob.py:609 - 开始写入输出文件...
2025-05-18 21:24:55,299 - getnode - INFO - nodesjob.py:618 - 成功生成订阅文件，总节点数: 27208
2025-05-18 21:24:55,305 - getnode - INFO - tester.py:74 - === 批量测试开始 | 总节点数: 27367 ===
2025-05-18 21:26:18,212 - getnode - INFO - tester.py:105 - === 批量测试完成 | 有效节点: 13964 (成功率: 51.0%) ===
2025-05-18 21:26:18,212 - getnode - INFO - nodesjob.py:591 - 开始保存节点结果到目录: speedtest
2025-05-18 21:26:18,318 - getnode - INFO - nodesjob.py:609 - 开始写入输出文件...
2025-05-18 21:26:23,442 - getnode - INFO - nodesjob.py:618 - 成功生成订阅文件，总节点数: 13961
2025-05-18 21:26:23,579 - getnode - INFO - main.py:81 - 
=== 文件处理统计 ===
• 扫描文件总数: 4229
• 因大小跳过:   80 (1.9%)
• 有效处理文件: 4149
=== 节点处理统计 ===
• 扫描节点总数: 61591
• 节点去重数:   34224
• 真实节点数:   27367
2025-05-18 16:02:46,848 - getnode - INFO - main.py:25 - === 开始执行爬虫任务 ===
2025-05-18 16:02:57,580 - getnode - INFO - crawler.py:130 - 仓库搜索完成 | 总扫描仓库: 180 有效仓库: 180 跳过: 0
2025-05-18 16:02:57,580 - getnode - INFO - main.py:30 - 发现 180 个相关仓库
2025-05-18 16:02:57,581 - getnode - INFO - main.py:34 - 开始收集节点文件...
2025-05-18 16:03:08,594 - getnode - INFO - crawler.py:50 - 已使用API次数: 100/小时
2025-05-18 16:03:20,069 - getnode - INFO - crawler.py:50 - 已使用API次数: 200/小时
2025-05-18 16:03:33,628 - getnode - INFO - crawler.py:50 - 已使用API次数: 300/小时
2025-05-18 16:03:44,752 - getnode - INFO - crawler.py:50 - 已使用API次数: 400/小时
2025-05-18 16:03:56,106 - getnode - INFO - crawler.py:50 - 已使用API次数: 500/小时
2025-05-18 16:04:07,212 - getnode - INFO - crawler.py:50 - 已使用API次数: 600/小时
2025-05-18 16:04:19,504 - getnode - INFO - crawler.py:50 - 已使用API次数: 700/小时
2025-05-18 16:04:32,138 - getnode - INFO - crawler.py:50 - 已使用API次数: 800/小时
2025-05-18 16:04:47,023 - getnode - INFO - crawler.py:50 - 已使用API次数: 900/小时
2025-05-18 16:04:59,854 - getnode - INFO - crawler.py:50 - 已使用API次数: 1000/小时
2025-05-18 16:05:11,939 - getnode - INFO - crawler.py:50 - 已使用API次数: 1100/小时
2025-05-18 16:05:24,685 - getnode - INFO - crawler.py:50 - 已使用API次数: 1200/小时
2025-05-18 16:05:36,360 - getnode - INFO - crawler.py:50 - 已使用API次数: 1300/小时
2025-05-18 16:05:48,871 - getnode - INFO - crawler.py:50 - 已使用API次数: 1400/小时
2025-05-18 16:06:00,143 - getnode - INFO - crawler.py:50 - 已使用API次数: 1500/小时
2025-05-18 16:06:12,773 - getnode - INFO - main.py:38 - 总共发现 188 个节点文件
2025-05-18 16:06:12,773 - getnode - INFO - nodesjob.py:18 - 开始处理链接集合，共 188 个链接
2025-05-18 16:06:35,689 - getnode - ERROR - nodesjob.py:69 - 处理链接时发生异常: 处理异常: 429 Client Error: Too Many Requests for url: https://raw.githubusercontent.com/lagzian/SS-Collector/main/ss_clash.yaml
Traceback (most recent call last):
  File "/home/runner/work/getnode/getnode/src/nodesjob.py", line 36, in parse_node_links
    response.raise_for_status()
  File "/opt/hostedtoolcache/Python/3.10.17/x64/lib/python3.10/site-packages/requests/models.py", line 1024, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 429 Client Error: Too Many Requests for url: https://raw.githubusercontent.com/lagzian/SS-Collector/main/ss_clash.yaml
2025-05-18 16:07:09,114 - getnode - INFO - nodesjob.py:74 - 链接处理完成。成功: 118, 失败: 70
2025-05-18 16:07:21,305 - getnode - INFO - history_manager.py:22 - 成功加载历史节点数量: 27367
2025-05-18 16:07:21,305 - getnode - INFO - history_manager.py:33 - 新节点：18040, 历史节点：27367
2025-05-18 16:07:21,668 - getnode - INFO - history_manager.py:52 - 合并后总节点数: 32840
2025-05-18 16:07:21,670 - getnode - INFO - nodesjob.py:560 - 开始保存节点结果到目录: output/all_subs
2025-05-18 16:07:21,967 - getnode - INFO - nodesjob.py:578 - 开始写入输出文件...
2025-05-18 16:07:37,498 - getnode - INFO - nodesjob.py:587 - 成功生成订阅文件，总节点数: 32530
2025-05-18 16:07:37,508 - getnode - INFO - tester.py:74 - === 批量测试开始 | 总节点数: 32840 ===
2025-05-18 16:18:48,929 - getnode - INFO - tester.py:103 - === 批量测试完成 | 有效节点: 11567 (成功率: 35.2%) ===
2025-05-18 16:18:48,929 - getnode - INFO - nodesjob.py:560 - 开始保存节点结果到目录: output/speedtest
2025-05-18 16:18:49,021 - getnode - INFO - nodesjob.py:578 - 开始写入输出文件...
2025-05-18 16:18:54,053 - getnode - INFO - nodesjob.py:587 - 成功生成订阅文件，总节点数: 11257
2025-05-18 16:18:54,195 - getnode - INFO - main.py:79 - 
=== 文件处理统计 ===
• 扫描文件总数: 10674
• 因大小跳过:   207 (1.9%)
• 有效处理文件: 10467
=== 节点处理统计 ===
• 扫描节点总数: 78558
• 节点去重数:   45718
• 真实节点数:   32840

